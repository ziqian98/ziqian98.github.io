---
layout: archive
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<h1 id="about-me" style="color: #0056b3;">About Me</h1>

<hr style="height: 1px; background-color: black; border: none;">

I am a research software engineer in Oracle Health and AI. I received my Master's degree in Computer Science from Carnegie Mellon University, advised by Prof. [Teruko Mitamura](https://www.cs.cmu.edu/~teruko/). 

In my previous experiences, I have a diverse academic and industrial background, including Multimodal AI, Model Compression & Efficient ML, Graph Neural Networks, Computer Vision, Natural Language Processing, AI for Healthcare, Data Augmentation, Large-Scale ML, Speech & Audio, and solid software engineering experiences in algorithm design, data structures, problem-solving, and complexity. I’m also active in academics and have served as a reviewer for many top-tier AI/ML conferences, like ICLR, ACL, NeurIPS, etc.

I have been contemplating how machines can transcend their computational limitations to comprehend human intelligence. My aim is to create computationally efficient machine learning and deep learning models and algorithms, establishing the computational foundations that will enable computers to analyze, recognize, and predict subtle human communicative behaviors in social interactions.


<h1 id="research-interests" style="color: #0056b3;">Research Interests</h1>

<hr style="height: 1px; background-color: black; border: none;">


`Multimodal Machine Learning`: representation, alignment, translation, fusion, and co-learning of heterogeneous data

`Natural Language Processing`: text representation, syntactic parsing, semantic analysis, text generation

`Multimodal Sentiment Analysis`: text, audio, video, facial expressions, and physiological signals

`Computer Vision`: image processing, object detection, image segmentation, scene understanding


<h1 id="services" style="color: #0056b3;">Services</h1>

<hr style="height: 1px; background-color: black; border: none;">

Conference/Journal reviewer: ACL, ICLR, AAAI, IJCAI, KDD, CVPR, NAACL, NeurIPS, ACMMM, Elsevier, Peerj, MDPI


<h1 id="education" style="color: #0056b3;">Education</h1>

<hr style="height: 1px; background-color: black; border: none;">

* M.S. in Computer Science, **Carnegie Mellon University**, Dec. 2020
* B.S. in Telecommunications Engineering, **Beijing University of Posts and Telecommunications**, Jun. 2019

<h1 id="experience" style="color: #0056b3;">Experience</h1>

<hr style="height: 1px; background-color: black; border: none;">

* ### Oracle 
  * **Software Engineer**, Feb 2021 - Current
    * Health and AI, Cloud Infrasturcture, Multi-Cloud Migration, Edge Cloud

* ### GEIRINA
  * **Machine Learning Engineer Intern**, May 2020 - Aug 2020
    * Maintained Deep Q Network with OpenAI Gym environment for smart power supply control for power plants


* ### Tencent
  * **Machine Learning Engineer Intern**, Apr 2019 - Jun 2019
    * Responsible for implementing Learn To Rank pipeline in WeChat AI


* ### Oracle
  * **Full Stack Software Engineer Intern**, Sep 2018 - Feb 2019
    * Created automation testing methods for testing UI and API actions in frontend and backend.

<h1 id="projects-publications" style="color: #0056b3;">Projects & Publications</h1>

<hr style="height: 1px; background-color: black; border: none;">
  

### Project 1: Cellular Macromolecules and Image Classification by Advanced Neural Network Strategies
<br />

  <div style="display: flex; align-items: center;">
    <div style="flex: 0 0 auto; margin-right: 10px;">
      <img src="/images/project3.jpg" alt="Image Title" width="300" height="300">
    </div>
    <div style="flex: 1 1 auto;">
      This project conducts an extensive investigation into advanced deep learning methodologies tailored for intricate challenges in image classification and the effective management of imbalanced datasets. It encompasses thorough research on convolutional neural networks (CNNs) optimized for various image recognition tasks, innovative strategies for mitigating the impact of data imbalance, and comprehensive evaluations of diverse neural network architectures. Highlighted applications include the classification of macromolecules using cellular electron tomography data, providing detailed insights into robust model architectures and methodologies aimed at significantly improving classification accuracy across a wide spectrum of image analysis domains.
    </div>
  </div>

  > #Imbalanced Data, #Cryo-Electron Tomography, #Image Classification, #Computational Biology

  * Publications
    * **Ziqian Luo**, Xiangrui Zeng, Min Xu, “Deep Learning-Based Strategy For Macromolecules Classification with Imbalanced Data from Cellular Electron Cryotomography,” Proc. of **IJCNN**’19, Budapest, Jul 2019.
    * Xueting Pan, **Ziqian Luo**, Lisang Zhou, "Comprehensive Survey of State-of-the-Art Convolutional Neural Network Architectures and Their Applications in Image Classification," In Journal of Innovations in Applied Engineering and Technology, 1(1), 1–16, Mar 2022.
    * Feiyang Chen, **Ziqian Luo**, Nan Chen, Hanyang Mao, Hanlin Hu, Ying Jiang, Xueting Pan, Huitao Zhang, "Assessing Four Neural Networks on Handwritten Digit Recognition Dataset (MNIST), " In Journal of Computer Science Research, 6(3), 17–22, July 2024.


<hr>

### Project 2: Unified AI Framework for Multimodal Multimedia Analysis and Efficient Distributed Computing
<br />

  <div style="display: flex; align-items: center;">
    <div style="flex: 0 0 auto; margin-right: 10px;">
      <img src="/images/project4.jpg" alt="Image Title" width="300" height="300">
    </div>
    <div style="flex: 1 1 auto;">
      This project aims to develop a comprehensive AI framework enhancing multimodal sentiment analysis, optimizing distributed file systems, and improving the deployment efficiency of advanced neural network models. By integrating techniques to fuse multiple features and modalities, it boosts sentiment analysis accuracy using both audio and text data. Simultaneously, it tackles distributed file system challenges by focusing on flexible, scalable, and resilient file storage solutions. Additionally, the project addresses Vision Transformer computational demands through optimized model compression techniques, balancing accuracy with efficiency for deployment in resource-constrained environments like edge computing devices. Through these efforts, the project seeks to create a unified AI framework that advances state-of-the-art in sentiment analysis, distributed computing, and practical deployment of neural network models across diverse technological domains.
    </div>
  </div>

  > #Vision Transformers, #Model Compression, #Edge Computing, #Resource Optimization, #Knowledge Distillation

  * Publications
    * Feiyang Chen, **Ziqian Luo**, Yanyan Xu, Dengfeng Ke, “Complementary fusion of multi-features and multi-modalities in sentiment analysis,” Proc. of the Thirty-fourth **AAAI** workshop, New York, Feb. 2020.
    * Xueting Pan, **Ziqian Luo**, Lisang Zhou, "Navigating the Landscape of Distributed File Systems: Architectures, Implementations, and Considerations," In Journal of Innovations in Applied Engineering and Technology, 2(1), 1–12, Nov 2023.
    * Feiyang Chen, **Ziqian Luo**, Lisang Zhou, Xueting Pan, Ying Jiang, “Comprehensive Survey of Model Compression and Speed up for Vision Transformers,” In Journal of Information, Technology and Policy, 1(1), 1–12, Apr 2024.


<hr>
    
### Project 3: Audio Sentiment Analysis by Deep Learning Models
<br />

  <div style="display: flex; align-items: center;">
    <div style="flex: 0 0 auto; margin-right: 10px;">
      <img src="/images/project1.jpg" alt="Image Title" width="300" height="300">
    </div>
    <div style="flex: 1 1 auto;">
      The project aims to explore the pioneering research in the field of multimodal audio-text sentiment analysis. Sentiment analysis has garnered widespread attention in both academia and industry in recent years, with most studies focusing on text-based sentiment analysis. However, real-world information often originates from multiple modalities, including audio and text. Therefore, in this project, we integrate audio and text, considering the task of multimodal sentiment analysis, and propose a novel fusion strategy comprising both multi-feature fusion and multi-modality fusion to enhance the accuracy of audio-text sentiment analysis. We introduce the DFF-ATMF (Deep Feature Fusion - Audio and Text Modality Fusion) model, consisting of two parallel branches: an audio modality-based branch and a text modality-based branch. Its core mechanisms involve the fusion of multiple feature vectors and attention mechanisms across multiple modalities. Through experiments conducted on the CMU-MOSI dataset and the recently released CMU-MOSEI dataset, sourced from YouTube for sentiment analysis, our DFF-ATMF model demonstrates highly competitive results. Additionally, leveraging attention weight distribution heatmaps, we illustrate the complementary and robust nature of the deep features learned by the DFF-ATMF model. Remarkably, our model also achieves new state-of-the-art results on the IEMOCAP dataset, underscoring the generalization capability of our proposed fusion strategy for multimodal emotion recognition.
    </div>
  </div>

  > #Multimodal Sentiment Analysis, #Emotion Recognition, #Deep Fusion Models

  * Publications
    * **Ziqian Luo**, Hua Xu, Feiyang Chen, “Audio Sentiment Analysis by Heterogeneous Signal Features Learned from Utterance-Based Parallel Neural Network,” Proc. of the Thirty-third **AAAI** workshop, Honolulu, Jan. 2019.
    * Feiyang Chen, **Ziqian Luo**, “Sentiment Analysis using Deep Robust Complementary Fusion of Multi-Features and Multi-Modalities,” arXiv preprint, Apr. 2019.
    * Feiyang Chen, **Ziqian Luo**, “Learning robust heterogeneous signal features from parallel neural network for audio sentiment analysis,” arXiv preprint, Jul. 2019.


<hr>

### Project 4: Innovative AI-Driven Summarization and Multimedia Generation Framework
<br />

  <div style="display: flex; align-items: center;">
    <div style="flex: 0 0 auto; margin-right: 10px;">
      <img src="/images/project2.jpg" alt="Image Title" style="border:0" width="300" height="300">
    </div>
    <div style="flex: 1 1 auto;">
      This project integrates cutting-edge advancements in natural language processing and multimedia generation to create a comprehensive AI-driven framework. By leveraging contextualized pre-trained models such as BERT and BART, the project explores innovative methods to enhance aspect-based abstractive summarization through the injection of external knowledge. This includes utilizing knowledge graphs and human-defined sequence-level scores to improve summarization accuracy and relevance. Simultaneously, the project addresses the challenges in Music Anime Douga (MAD) production, a popular form of multimedia that combines animation with music. It introduces a novel framework for generating high-quality videos from text-image pairs, overcoming the limitations of existing text-to-video synthesis methods. This multi-modal system interprets narrative and visual inputs to produce seamless video outputs, enhancing artistic control and preserving the creator's intent. By combining these two advanced AI applications, the project aims to revolutionize both text summarization and multimedia content creation, democratizing the production process and encouraging broader artistic participation and innovation. Through rigorous experimentation and validation, this integrated framework sets the stage for future advancements in AI-assisted content generation and summarization technologies.
    </div>
  </div>

  > #Pre-trained Models, #Knowledge Graph, #Natural Language Processing

  * Publications
    * **Ziqian Luo**, "Knowledge-guided Aspect-based Summarization," Proc. of the International Conference on Communications, Computing and Artificial Intelligence **CCCAI**, Jun 2023.
    * Lisang Zhou, **Ziqian Luo**, Xueting Pan, "Machine learning-based system reliability analysis with Gaussian Process Regression", In Journal of Computational Methods in Engineering Application, 3(1), 1–23, Nov 2023.
    * **Ziqian Luo**, Feiyang Chen, Xueting Pan, "A Novel Framework for Text-Image Pair to Video Generation in Music Anime Douga (MAD) Production", In Journal of Artificial Intelligence Advances, Jun 2024
    
    



<!--

This is the front page of a website that is powered by the [academicpages template](https://github.com/academicpages/academicpages.github.io) and hosted on GitHub pages. [GitHub pages](https://pages.github.com) is a free service in which websites are built and hosted from code and data stored in a GitHub repository, automatically updating when a new commit is made to the respository. This template was forked from the [Minimal Mistakes Jekyll Theme](https://mmistakes.github.io/minimal-mistakes/) created by Michael Rose, and then extended to support the kinds of content that academics have: publications, talks, teaching, a portfolio, blog posts, and a dynamically-generated CV. You can fork [this repository](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and markdown files, add your own PDFs and other content, and have your own site for free, with no ads! An older version of this template powers my own personal website at [stuartgeiger.com](http://stuartgeiger.com), which uses [this Github repository](https://github.com/staeiou/staeiou.github.io).

A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.

-->
